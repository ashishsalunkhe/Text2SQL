import streamlit as st
import openai
import sqlite3
import pandas as pd
import json
import os
import requests
import nltk
import logging
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# === Logging Setup ===
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# === NLTK Safe Downloader ===
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

# === Paths ===
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")
DB_PATH = os.path.join(DATA_DIR, "mimic_iii.db")
SCHEMA_JSON_PATH = os.path.join(DATA_DIR, "schema_map.json")
LOG_PATH = os.path.join(DATA_DIR, "query_log.csv")

# === Load Schema ===
@st.cache_data
def load_schema():
    try:
        with open(SCHEMA_JSON_PATH) as f:
            schema = json.load(f)
            logger.info("Schema loaded from JSON.")
            return schema
    except Exception as e:
        logger.error(f"Error loading schema: {e}")
        st.error("Failed to load schema.")

# === Prompt Builder ===
def format_schema(schema_json):
    return "\n\n".join(
        [f"Table: {tbl}\nColumns: {', '.join(meta['columns'])}" for tbl, meta in schema_json.items()]
    )

def build_prompt(user_question, schema_json):
    context = """
Helpful Notes:
- Use subject_id or hadm_id to link patient-level tables.
- diagnoses_icd.icd9_code LIKE '250%' means diabetes.
- patients.hospital_expire_flag = 1 means patient died.
- microbiologyevents.org_name is for organisms.
- d_labitems.label gives lab test names via labevents.itemid = d_labitems.itemid
- labevents + icustays join via subject_id or hadm_id
"""
    prompt = f"""
You are a medical SQL assistant.

{context}

Schema:
{format_schema(schema_json)}

User question:
\"{user_question}\"

Return only the SQLite SQL query.
"""
    logger.info("Prompt built successfully.")
    return prompt

# === GPT Query Generator ===
def get_sql_from_gpt(prompt):
    openai.api_key = st.secrets["OPENAI_API_KEY"]
    try:
        res = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        sql = res["choices"][0]["message"]["content"].strip().replace("```sql", "").replace("```", "").strip()
        logger.info("SQL query generated by GPT.")
        return sql
    except Exception as e:
        logger.error(f"OpenAI GPT error: {e}")
        st.error("Failed to generate SQL from GPT.")

# === SQL Executor ===
def run_sql(query):
    try:
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute(query)
        rows = cur.fetchall()
        cols = [desc[0] for desc in cur.description]
        conn.close()
        logger.info("SQL query executed successfully.")
        return pd.DataFrame(rows, columns=cols)
    except Exception as e:
        logger.error(f"SQL execution failed: {e}")
        raise e

# === ICD Lookup ===
def get_icd9_description(code, table="d_icd_diagnoses"):
    try:
        conn = sqlite3.connect(DB_PATH)
        query = f"SELECT SHORT_TITLE, LONG_TITLE FROM {table} WHERE ICD9_CODE LIKE ? LIMIT 1"
        df = pd.read_sql(query, conn, params=(code + '%',))
        conn.close()
        if not df.empty:
            return f"**{code}**: {df.iloc[0]['SHORT_TITLE']} ‚Äì {df.iloc[0]['LONG_TITLE']}"
    except Exception as e:
        logger.warning(f"ICD lookup failed for {code}: {e}")
    return None

# === Augmented Term Extraction & Wiki Context ===
def extract_medical_terms(question):
    stop_words = set(stopwords.words('english'))
    words = word_tokenize(question.lower())
    return [w for w in words if w.isalpha() and w not in stop_words and len(w) > 3]

def fetch_medical_context(terms):
    summaries = {}
    for term in terms:
        try:
            url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{term}"
            res = requests.get(url)
            if res.status_code == 200:
                data = res.json()
                if 'extract' in data and len(data['extract']) > 100:
                    summaries[term] = data['extract']
                    logger.info(f"Fetched context for term: {term}")
        except Exception as e:
            logger.warning(f"Failed to fetch context for {term}: {e}")
    return summaries

# === Logging ===
def log_interaction(question, sql_query, result_df):
    log_entry = {
        "question": question,
        "sql_query": sql_query,
        "result_preview": result_df.head().to_json(orient="records")
    }
    df = pd.DataFrame([log_entry])
    mode = 'a' if os.path.exists(LOG_PATH) else 'w'
    header = not os.path.exists(LOG_PATH)
    df.to_csv(LOG_PATH, mode=mode, header=header, index=False)
    logger.info("Logged query interaction.")

def load_query_history():
    if os.path.exists(LOG_PATH):
        logger.info("Query history loaded.")
        return pd.read_csv(LOG_PATH)
    return pd.DataFrame(columns=["question", "sql_query", "result_preview"])

# === UI Starts ===
st.set_page_config(page_title="MIMIC-III SQL Explorer", layout="wide")
st.title("ü©∫ MIMIC-III Natural Language SQL Explorer")

# --- Query History ---
with st.expander("üïò Query History", expanded=False):
    history_df = load_query_history()
    if not history_df.empty:
        history_df['result_preview'] = history_df['result_preview'].astype(str)
        display_df = history_df[["question", "sql_query", "result_preview"]].rename(columns={
            "question": "Question", "sql_query": "SQL Query", "result_preview": "Result"
        }).sort_index(ascending=False)
        st.dataframe(display_df)

        st.download_button("üì• Download Query History", display_df.to_csv(index=False).encode("utf-8"),
                           file_name="query_history.csv", mime="text/csv")

        selected = st.selectbox("üîÅ Re-run query", display_df["Question"])
        rerun_row = display_df[display_df["Question"] == selected].iloc[0]
        st.code(rerun_row["SQL Query"], language="sql")
        try:
            df = run_sql(rerun_row["SQL Query"])
            st.dataframe(df)
        except Exception as e:
            st.error(f"Execution failed: {e}")
    else:
        st.info("No queries logged yet.")

# --- New Question ---
user_question = st.text_input("Ask a clinical question:")

if user_question:
    schema = load_schema()
    prompt = build_prompt(user_question, schema)
    with st.spinner("Generating SQL..."):
        try:
            sql_query = get_sql_from_gpt(prompt)
            st.code(sql_query, language='sql')
            result_df = run_sql(sql_query)
            st.dataframe(result_df)

            if "ICD9_CODE" in result_df.columns:
                st.markdown("### üßæ ICD Descriptions")
                for code in result_df["ICD9_CODE"].dropna().unique()[:5]:
                    desc = get_icd9_description(code)
                    if desc:
                        st.markdown(f"- {desc}")

            if st.checkbox("üìò Add Clinical Context"):
                terms = extract_medical_terms(user_question)
                summaries = fetch_medical_context(terms)
                if summaries:
                    st.caption(f"üîç Found terms: {', '.join(summaries.keys())}")
                    for term, info in summaries.items():
                        with st.expander(term.title()):
                            st.markdown(info)
                else:
                    st.info("No relevant clinical context found.")

            log_interaction(user_question, sql_query, result_df)
        except Exception as e:
            st.error(f"SQL execution failed: {e}")
            logger.error(f"Query failed: {e}")

# --- Manual SQL ---
with st.expander("üßÆ Run Manual SQL Query"):
    manual_sql = st.text_area("Enter your SQL query here (SELECT-only):")
    if manual_sql:
        if any(word in manual_sql.upper() for word in ["DROP", "DELETE", "UPDATE", "INSERT"]):
            st.error("‚ùå Destructive SQL statements are not allowed.")
            logger.warning("Blocked destructive SQL query.")
        else:
            try:
                df = run_sql(manual_sql)
                st.dataframe(df)
                logger.info("Manual SQL executed successfully.")
            except Exception as e:
                st.error(f"Execution failed: {e}")
                logger.error(f"Manual SQL error: {e}")